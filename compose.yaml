# FFprobe API - Modern Docker Compose Application
# Uses latest Docker Compose Application Model
# https://docs.docker.com/compose/intro/compose-application-model/

name: ffprobe-api

# Service definitions using latest features
services:
  # Main API service with latest FFmpeg from BtbN
  api:
    build:
      context: .
      dockerfile: Dockerfile.btbn
      args:
        - BUILDKIT_INLINE_CACHE=1
      cache_from:
        - ffprobe-api:latest
      target: production
    image: ffprobe-api:latest
    container_name: ffprobe-api
    hostname: ffprobe-api
    ports:
      - target: 8080
        published: 8080
        protocol: tcp
        mode: host
    environment:
      GO_ENV: ${GO_ENV:-development}
      API_PORT: 8080
      HOST: 0.0.0.0
    env_file:
      - path: .env
        required: false
    volumes:
      - type: volume
        source: uploads
        target: /app/uploads
      - type: volume
        source: reports
        target: /app/reports
      - type: volume
        source: temp
        target: /app/temp
      - type: volume
        source: cache
        target: /app/cache
    depends_on:
      postgres:
        condition: service_healthy
        restart: true
      redis:
        condition: service_healthy
        restart: true
      ollama:
        condition: service_started
        restart: true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
      start_interval: 5s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,version"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.api.rule=Host(`localhost`)"
      - "com.ffprobe-api.service=api"
      - "com.ffprobe-api.version=latest"
    networks:
      - ffprobe-network
    profiles:
      - api
      - quick
      - minimal
      - full

  # PostgreSQL 16 with modern configuration
  postgres:
    image: postgres:16-alpine
    container_name: ffprobe-postgres
    hostname: postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ffprobe_api}
      POSTGRES_USER: ${POSTGRES_USER:-ffprobe}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-quickstart123}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
      # Performance tuning
      POSTGRES_SHARED_PRELOAD_LIBRARIES: pg_stat_statements
      POSTGRES_MAX_CONNECTIONS: 100
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
    volumes:
      - type: volume
        source: postgres_data
        target: /var/lib/postgresql/data
      - type: volume
        source: postgres_backup
        target: /backup
      - type: bind
        source: ./migrations
        target: /docker-entrypoint-initdb.d
        read_only: true
    ports:
      - target: 5432
        published: ${POSTGRES_PORT:-5432}
        protocol: tcp
        mode: host
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ffprobe} -d ${POSTGRES_DB:-ffprobe_api}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
      start_interval: 2s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      - "com.ffprobe-api.service=database"
      - "com.ffprobe-api.version=16"
    networks:
      - ffprobe-network
    profiles:
      - database
      - quick
      - minimal
      - full

  # Redis 7 with persistence and clustering support
  redis:
    image: redis:7-alpine
    container_name: ffprobe-redis
    hostname: redis
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-quickstart123}
      --appendonly yes
      --appendfsync everysec
      --save 900 1
      --save 300 10
      --save 60 10000
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 0
    volumes:
      - type: volume
        source: redis_data
        target: /data
      - type: tmpfs
        target: /tmp
        tmpfs:
          size: 100M
    ports:
      - target: 6379
        published: ${REDIS_PORT:-6379}
        protocol: tcp
        mode: host
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-quickstart123}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
      start_interval: 1s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"
    labels:
      - "com.ffprobe-api.service=cache"
      - "com.ffprobe-api.version=7"
    networks:
      - ffprobe-network
    profiles:
      - cache
      - quick
      - minimal
      - full

  # Ollama with AI models - optimized for latest features
  ollama:
    image: ollama/ollama:latest
    container_name: ffprobe-ollama
    hostname: ollama
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_MODELS: ${OLLAMA_MODEL:-gemma3:270m},${OLLAMA_FALLBACK_MODEL:-phi3:mini}
      OLLAMA_NUM_PARALLEL: 2
      OLLAMA_MAX_QUEUE: 512
      OLLAMA_KEEP_ALIVE: 5m
    volumes:
      - type: volume
        source: ollama_data
        target: /root/.ollama
      - type: tmpfs
        target: /tmp
        tmpfs:
          size: 2G
    ports:
      - target: 11434
        published: 11434
        protocol: tcp
        mode: host
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 6G
        reservations:
          cpus: '1'
          memory: 2G
      # Uncomment for GPU support
      # devices:
      #   - driver: nvidia
      #     count: 1
      #     capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s
      start_interval: 5s
    logging:
      driver: json-file
      options:
        max-size: "20m"
        max-file: "3"
    labels:
      - "com.ffprobe-api.service=ai"
      - "com.ffprobe-api.models=${OLLAMA_MODEL:-gemma3:270m},${OLLAMA_FALLBACK_MODEL:-phi3:mini}"
    networks:
      - ffprobe-network
    profiles:
      - ai
      - quick
      - minimal
      - full
    # Model initialization using modern init containers pattern
    init: true
    entrypoint: ["/bin/sh"]
    command: >
      -c "
        echo 'Starting Ollama service...'
        ollama serve &
        OLLAMA_PID=$$!
        
        echo 'Waiting for Ollama to be ready...'
        timeout=60
        while [ $$timeout -gt 0 ]; do
          if curl -s http://localhost:11434/api/version >/dev/null 2>&1; then
            echo 'Ollama is ready!'
            break
          fi
          sleep 2
          timeout=$$((timeout-1))
        done
        
        if [ $$timeout -eq 0 ]; then
          echo 'Ollama failed to start'
          exit 1
        fi
        
        echo 'Downloading AI models...'
        echo 'Primary model: ${OLLAMA_MODEL:-gemma3:270m}'
        ollama pull ${OLLAMA_MODEL:-gemma3:270m} || echo 'Primary model download failed'
        
        echo 'Fallback model: ${OLLAMA_FALLBACK_MODEL:-phi3:mini}'
        ollama pull ${OLLAMA_FALLBACK_MODEL:-phi3:mini} || echo 'Fallback model download failed'
        
        echo 'Available models:'
        ollama list
        
        echo 'Model setup complete! Keeping service running...'
        wait $$OLLAMA_PID
      "

# Modern volume definitions with labels and driver options
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/postgres
    labels:
      - "com.ffprobe-api.volume=database"
      - "com.ffprobe-api.backup=daily"
  postgres_backup:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${BACKUP_PATH:-./backup}/postgres
    labels:
      - "com.ffprobe-api.volume=backup"
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/redis
    labels:
      - "com.ffprobe-api.volume=cache"
      - "com.ffprobe-api.backup=weekly"
  ollama_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/ollama
    labels:
      - "com.ffprobe-api.volume=ai-models"
      - "com.ffprobe-api.backup=monthly"
  uploads:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/uploads
    labels:
      - "com.ffprobe-api.volume=user-data"
      - "com.ffprobe-api.backup=daily"
  reports:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/reports
    labels:
      - "com.ffprobe-api.volume=generated-reports"
      - "com.ffprobe-api.backup=weekly"
  temp:
    driver: local
    labels:
      - "com.ffprobe-api.volume=temporary"
      - "com.ffprobe-api.cleanup=daily"
  cache:
    driver: local
    labels:
      - "com.ffprobe-api.volume=cache"
      - "com.ffprobe-api.cleanup=weekly"

# Modern network configuration with custom driver and IPAM
networks:
  ffprobe-network:
    driver: bridge
    enable_ipv6: false
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
          ip_range: 172.20.240.0/20
    driver_opts:
      com.docker.network.bridge.name: ffprobe-br0
      com.docker.network.driver.mtu: 1500
    labels:
      - "com.ffprobe-api.network=main"
      - "com.ffprobe-api.environment=${GO_ENV:-development}"

# Configuration for different environments using profiles
# Usage: docker compose --profile development up
# Usage: docker compose --profile production up
# Usage: docker compose --profile full up (all services)

# Extensions for reusable configuration
x-common-variables: &common-variables
  TZ: ${TZ:-UTC}
  LANG: en_US.UTF-8
  LC_ALL: en_US.UTF-8

x-restart-policy: &restart-policy
  restart: unless-stopped

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"
    labels: "service,version,environment"

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s
  start_interval: 5s

# Include additional compose files based on environment
include:
  - path: compose.override.yaml
    required: false
  - path: compose.${GO_ENV:-development}.yaml
    required: false
  - path: compose.local.yaml
    required: false