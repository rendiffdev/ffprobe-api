# FFprobe API - Production Environment
# Modern Docker Compose for production deployment
# Usage: docker compose --profile production up

name: ffprobe-api-prod

# Production-specific service configurations
services:
  # Production API with high availability
  api:
    extends:
      file: compose.yaml
      service: api
    image: ffprobe-api:latest
    container_name: ffprobe-api-prod
    hostname: ffprobe-api-prod
    environment:
      GO_ENV: production
      GIN_MODE: release
      LOG_LEVEL: info
      # Database Configuration (SQLite embedded)
      DB_TYPE: sqlite
      DB_PATH: /app/data/ffprobe.db
      # Cache Configuration (Valkey - Redis compatible)
      VALKEY_HOST: valkey-prod
      VALKEY_PORT: 6379
      VALKEY_PASSWORD: ${VALKEY_PASSWORD:-changeme}
      # Production security settings
      ENABLE_AUTH: true
      ENABLE_RATE_LIMIT: true
      ENABLE_CSRF: true
      # Performance settings
      WORKER_POOL_SIZE: 16
      MAX_CONCURRENT_JOBS: 8
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 60s
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 10s
        failure_action: pause
        monitor: 30s
        order: stop-first
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
      start_interval: 5s
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"
        labels: "service,version,environment=production"
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=traefik-network"
      # Main API Router
      - "traefik.http.routers.api-prod.rule=Host(`api.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.api-prod.entrypoints=websecure"
      - "traefik.http.routers.api-prod.tls=true"
      - "traefik.http.routers.api-prod.tls.certresolver=letsencrypt"
      - "traefik.http.routers.api-prod.service=api-prod"
      # HTTP to HTTPS redirect
      - "traefik.http.routers.api-prod-http.rule=Host(`api.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.api-prod-http.entrypoints=web"
      - "traefik.http.routers.api-prod-http.middlewares=https-redirect"
      # Service configuration
      - "traefik.http.services.api-prod.loadbalancer.server.port=8080"
      # Security middleware
      - "traefik.http.middlewares.https-redirect.redirectscheme.scheme=https"
      - "traefik.http.middlewares.secure-headers.headers.sslredirect=true"
      - "traefik.http.middlewares.secure-headers.headers.stsSeconds=31536000"
      - "traefik.http.middlewares.secure-headers.headers.stsIncludeSubdomains=true"
    profiles:
      - production
      - prod
      - api-prod
    networks:
      - ffprobe-prod-network
      - traefik-network

  # Production Valkey (Redis-compatible, open source)
  valkey:
    image: valkey/valkey:8.0-alpine
    container_name: ffprobe-valkey-prod
    hostname: valkey-prod
    command: >
      valkey-server
      --requirepass ${VALKEY_PASSWORD:-changeme}
      --appendonly yes
      --appendfsync everysec
      --save 900 1
      --save 300 10
      --save 60 10000
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 0
      --databases 16
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    volumes:
      - type: volume
        source: valkey_prod_data
        target: /data
    healthcheck:
      test: ["CMD", "valkey-cli", "-a", "${VALKEY_PASSWORD:-changeme}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    profiles:
      - production
      - prod
      - cache-prod
    networks:
      - ffprobe-prod-network

  # Production Ollama with optimizations
  ollama:
    extends:
      file: compose.yaml
      service: ollama
    image: ollama/ollama:latest
    container_name: ffprobe-ollama-prod
    hostname: ollama-prod
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_MODELS: ${OLLAMA_MODEL},${OLLAMA_FALLBACK_MODEL}
      OLLAMA_NUM_PARALLEL: 4
      OLLAMA_MAX_QUEUE: 1024
      OLLAMA_KEEP_ALIVE: 10m
      OLLAMA_FLASH_ATTENTION: true
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - type: volume
        source: ollama_prod_data
        target: /root/.ollama
      - type: tmpfs
        target: /tmp
        tmpfs:
          size: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 300s
      start_interval: 10s
    profiles:
      - production
      - prod
      - ai-prod
    networks:
      - ffprobe-prod-network

  # Traefik - Combined reverse proxy and SSL termination
  traefik:
    image: traefik:v3.0
    container_name: ffprobe-traefik
    hostname: traefik
    command:
      # API Configuration
      - "--api.dashboard=true"
      - "--api.debug=false"
      - "--log.level=INFO"
      # Docker Provider
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.network=traefik-network"
      # Entry Points
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      # SSL/TLS Configuration
      - "--certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}"
      - "--certificatesresolvers.letsencrypt.acme.storage=/acme.json"
      - "--certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web"
      # Redirect HTTP to HTTPS
      - "--entrypoints.web.http.redirections.entrypoint.to=websecure"
      - "--entrypoints.web.http.redirections.entrypoint.scheme=https"
      # Security Headers
      - "--entrypoints.websecure.http.tls.options=modern@file"
      # Metrics
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.addEntryPointsLabels=true"
      - "--metrics.prometheus.addServicesLabels=true"
      # Access Logs
      - "--accesslog=true"
      - "--accesslog.format=json"
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - target: 8080
        published: 8180
        protocol: tcp
        mode: host
    volumes:
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
        read_only: true
      - type: volume
        source: traefik_acme
        target: /acme.json
    healthcheck:
      test: ["CMD", "traefik", "healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=traefik-network"
      - "traefik.http.routers.traefik-dashboard.rule=Host(`traefik.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.traefik-dashboard.entrypoints=websecure"
      - "traefik.http.routers.traefik-dashboard.tls=true"
      - "traefik.http.routers.traefik-dashboard.tls.certresolver=letsencrypt"
      - "traefik.http.routers.traefik-dashboard.service=api@internal"
    profiles:
      - production
      - prod
      - traefik
    networks:
      - traefik-network

  # Prometheus monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: ffprobe-prometheus
    hostname: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--web.external-url=https://prometheus.${DOMAIN:-localhost}'
    ports:
      - target: 9090
        published: 9090
        protocol: tcp
    volumes:
      - type: bind
        source: ./config/prometheus/prometheus.yml
        target: /etc/prometheus/prometheus.yml
        read_only: true
      - type: bind
        source: ./config/prometheus/rules
        target: /etc/prometheus/rules
        read_only: true
      - type: volume
        source: prometheus_data
        target: /prometheus
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.prometheus.tls=true"
    profiles:
      - production
      - prod
      - monitoring
    networks:
      - ffprobe-prod-network
      - traefik-network

  # Grafana dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: ffprobe-grafana
    hostname: grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_SERVER_DOMAIN: grafana.${DOMAIN:-localhost}
      GF_SERVER_ROOT_URL: https://grafana.${DOMAIN:-localhost}
      GF_INSTALL_PLUGINS: redis-datasource,grafana-clock-panel,grafana-worldmap-panel
      GF_FEATURE_TOGGLES_ENABLE: publicDashboards
      GF_DATABASE_TYPE: sqlite3
      GF_DATABASE_PATH: /var/lib/grafana/grafana.db
    ports:
      - target: 3000
        published: 3000
        protocol: tcp
    volumes:
      - type: volume
        source: grafana_data
        target: /var/lib/grafana
      - type: bind
        source: ./config/grafana/dashboards
        target: /etc/grafana/provisioning/dashboards
        read_only: true
      - type: bind
        source: ./config/grafana/datasources
        target: /etc/grafana/provisioning/datasources
        read_only: true
    depends_on:
      prometheus:
        condition: service_healthy
      valkey:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.grafana.tls=true"
    profiles:
      - production
      - prod
      - monitoring
    networks:
      - ffprobe-prod-network
      - traefik-network

  # Automated backup service
  backup:
    image: alpine:latest
    container_name: ffprobe-backup
    hostname: backup
    environment:
      DB_TYPE: sqlite
      DB_PATH: /app/data/ffprobe.db
      BACKUP_RETENTION_DAYS: 30
      BACKUP_ENCRYPTION_KEY: ${BACKUP_ENCRYPTION_KEY}
      S3_BUCKET: ${BACKUP_S3_BUCKET}
      S3_ACCESS_KEY: ${BACKUP_S3_ACCESS_KEY}
      S3_SECRET_KEY: ${BACKUP_S3_SECRET_KEY}
    volumes:
      - type: volume
        source: sqlite_prod_data
        target: /app/data
        read_only: true
      - type: volume
        source: valkey_prod_data
        target: /valkey/data
        read_only: true
      - type: volume
        source: backup_scripts
        target: /scripts
      - type: bind
        source: ./scripts/backup
        target: /backup-scripts
        read_only: true
    entrypoint: ["/bin/sh"]
    command: >
      -c "
        apk add --no-cache sqlite aws-cli gnupg
        echo '0 2 * * * /backup-scripts/backup.sh' | crontab -
        echo '0 4 * * 0 /backup-scripts/cleanup.sh' | crontab -
        crond -f
      "
    depends_on:
      valkey:
        condition: service_healthy
    restart: unless-stopped
    profiles:
      - production
      - prod
      - backup
    networks:
      - ffprobe-prod-network

# Production volumes with specific drivers and options
volumes:
  sqlite_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH}/sqlite
    labels:
      - "com.ffprobe-api.volume=production-database"
      - "com.ffprobe-api.backup=daily"
      - "com.ffprobe-api.type=sqlite"
  valkey_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH}/valkey
    labels:
      - "com.ffprobe-api.volume=production-cache"
      - "com.ffprobe-api.backup=weekly"
      - "com.ffprobe-api.type=valkey"
  ollama_prod_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH}/ollama
    labels:
      - "com.ffprobe-api.volume=production-ai-models"
      - "com.ffprobe-api.backup=monthly"
  traefik_acme:
    driver: local
    labels:
      - "com.ffprobe-api.volume=acme-certificates"
      - "com.ffprobe-api.backup=daily"
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH}/prometheus
    labels:
      - "com.ffprobe-api.volume=metrics-data"
      - "com.ffprobe-api.retention=30d"
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH}/grafana
    labels:
      - "com.ffprobe-api.volume=dashboards-data"
      - "com.ffprobe-api.backup=weekly"
  backup_scripts:
    driver: local
    labels:
      - "com.ffprobe-api.volume=backup-scripts"

# Production networks with security and monitoring
networks:
  ffprobe-prod-network:
    driver: bridge
    enable_ipv6: false
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.0/16
          gateway: 172.22.0.1
          ip_range: 172.22.240.0/20
    driver_opts:
      com.docker.network.bridge.name: ffprobe-prod-br0
      com.docker.network.driver.mtu: 1500
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "true"
    labels:
      - "com.ffprobe-api.network=production"
      - "com.ffprobe-api.environment=production"
      - "com.ffprobe-api.security=high"

  traefik-network:
    driver: bridge
    enable_ipv6: false
    ipam:
      driver: default
      config:
        - subnet: 172.23.0.0/16
          gateway: 172.23.0.1
    driver_opts:
      com.docker.network.bridge.name: traefik-br0
    labels:
      - "com.ffprobe-api.network=edge"
      - "com.ffprobe-api.purpose=reverse-proxy"

# Production-specific configurations
x-production-variables: &prod-variables
  GO_ENV: production
  NODE_ENV: production
  LOG_LEVEL: info
  TZ: UTC

x-production-logging: &prod-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "5"
    labels: "service,version,environment=production"
    tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"

x-production-security: &prod-security
  security_opt:
    - no-new-privileges:true
  cap_drop:
    - ALL
  cap_add:
    - CHOWN
    - DAC_OVERRIDE
    - FOWNER
    - SETGID
    - SETUID